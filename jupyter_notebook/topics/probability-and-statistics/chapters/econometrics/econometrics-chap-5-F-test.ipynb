{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three topics that are central to hypothesis testing are\n",
    "- the specification of the hypothesis to be tested\n",
    "- the decision rule to use in deciding whether to rejected the hypothesis\n",
    "- the kinds of errors that might be encountered if the application of the decision rule to the appropriate statistics yields an incorrect reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $F$-Test\n",
    "Although the $t$-test is invaluable for hypotheses about individual regression coefficients, it cannot be used to test multiple hypotheses **simultaneously**. For example, say you want to test the null hypothesis that there is no seasonal variation in a quarterly regression equation that has dummy variables for the seasons. For such hypotheses, most researchers will use the $F$-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the ${F}$-Test?\n",
    "\n",
    "The $F$-test is a formal hypothesis test that is designed to deal with a null hypothesis which contains multiple hypotheses or a single hypothesis about a group of coefficients. Such \"joint\" or \"compound\" null hypotheses are appropriate whenever the underline economic theory specifies values for multiple coefficients simultaneously.\n",
    "\n",
    "First translate the particular null hypothesis to constraints that will be placed in the equation. The resulting constrained equation can be though of as what the equation would look like if the null hypothesis were correct - you substitute the hypothesized values into the regression equation in order to see what would happen if the equation was constrained to agree with the null hypothesis. As a result, in the $F$-test the null hypothesis always leads to a constrained equation even if this violates our standard practice that the alternative hypothesis contains that we expect is true.\n",
    "\n",
    "Second, estimate this constrained equation with OLS and compare the fit of this constrained equation with the fit of the un-constrained equation. If the fits of the constrained equation and the unconstrained equation are not significantly different, the null hypothesis should *not* be rejected. If the fit of the unconstrained equation is significantly better than that of the unconstrained equation, we reject the null hypothesis. The fit of the constrained equation is **never** superior to the fit of the unconstrained equation. The fits of the equations are compared with the general $F$-statistic where\n",
    "$$\\begin{align}\n",
    "F = \\frac{\\frac{(\\text{RSS}_M-\\text{RSS})}{M}}{\\frac{\\text{RSS}}{N-K-1}}\\end{align}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\text{RSS}$ is the residual sum of squares from the unconstrained equation\n",
    "- $\\text{RSS}_M$ is the residual sum of squares from the constrained equation\n",
    "- $M$ is the number of constraints placed on the equation\n",
    "- $(N-K-1)$ is the degrees of freedom in the ${unconstrained} equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{RSS}_M$ is **always** greater than or equal to $\\text{RSS}$. Imposing constraints on the coefficients instead of allowing OLS to select their values can never decrease the summed squared residuals. If the unconstrained regression yields exactly the same estimated coefficients as does the constrained regression, the RSS are equal and the $F$-statistic is zero. In this case, $\\text{H}_0$ is not rejected because the data indicate that the constraints appear to be correct. As the difference between the constrained coefficients and the unconstrained coefficients increases, the data indicate that the null hypothesis is less likely to be true. Thus, when $F$ gets larger than the critical $F$-value, the hypothesized restrictions specified in the null hypothesis are rejected by the test.\n",
    "\n",
    "The decision rule to use in the $F$-test is to reject the null hypothesis if the calculated $F$-value is greater than the appropriate critical $F$-value, $F_C$.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "- Reject H$_0$ if  $F \\geq F_C$. <br/>\n",
    "- Do not reject H$_0$ if $F < F_C$\n",
    "\\end{description}</div>\n",
    "\n",
    "The critical $F$-value, $F_C$ is determined from statistical tables depending on a level of significance chosen by the researcher and on the degrees of freedom. The $F$-statistic has two types of degrees of freedom: the degrees of freedom for the numerator of (2) due to $M$ and the degrees of freedom for the denominator due to $(N-K-1)$. The underlying principle here is that the if the calculated $F$-value is greater than the critical value then the estimated equation's fit is significantly better than the constrained equation's fit, and we can reject the null hypotheiss of no effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $F$-Test of Overall Significance\n",
    "\n",
    "Although $R^2$ and $\\bar{R}^2$ measure the overall degree of fit of an equation, they don't provide a formal hypothesis test of that overall fit. Such a test is provided by the ${F}$-test. The null hypothesis in an ${F}$-test of overall significance is that all the slope coefficients in the equation equal zero simultaneously. For an equation with $K$ independent variables, this means that the null and alternative hypothesis would be:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{H}_0 & \\text{: }\\beta_1 = \\beta_2=\\beta_3 = \\cdots = 0\\\\ \n",
    "\\text{H}_\\text{A} & \\text{: } \\text{H}_0 \\text{ is not true}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "To show that the overall fit of the estimated equation is statistically significant, we must be able to reject this null hypothesis using the ${F}$-test. For the ${F}$-test of overall significance, () simplifies to\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "F = \\frac{\\frac{\\text{ESS}}{K}}{\\frac{\\text{RSS}}{N-K-1}} = \\frac{\\sum_i(\\hat{Y_i} - \\bar{Y})^2}{\\frac{\\sum_i e_i^2}{(N-K-1)}} \\label{eg5_12}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "This is the ratio of the explained sum of squares ($\\text{ESS}$) to the residual sum of squares ($\\text{RSS}$), adjusted for the number of independent variables, $K$, and the number of observations in the sample, $N$. In this case, the \"constrained\" equation to which we are comparing the overall fit is :\n",
    "$$\n",
    "Y_i = \\beta_0 + \\epsilon_i \n",
    "$$\n",
    "which is nothing more than saying that $\\hat{\\beta_i} = \\bar{Y}$. Thus the ${F}$-test of overall significance is really testing the null hypothesis that the fit of the equation isn't significantly better than that provided by using the mean alone.\n",
    "\n",
    "Two comments of the ${F}$-test. First, if there is only one independent variable, then an ${F}$-test and a ${t}$-test of whether the slope coefficient equals zero will always produce the same answer. This property does not hold if there ar two or more independent variables. In such a situation, an ${F}$-test could determine that the coefficients *jointly* are not significantly different from zero even though a ${t}-test on one of the coefficients might show that *individually* it is significantly different from zero. The vice versa holds too.\n",
    "\n",
    "Second, just as ${p}$-values provide an alternative approach to the ${t}$-test, so too can ${p}$-values provide an alternative approach to the ${F}$-test of overall significance. Most standard regression estimation programs report both the ${F}$-value and the ${p}$-value associated with this test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Uses of the ${F}$-Test\n",
    "\n",
    "Besides the test of overall significance, there are many other uses of the ${F}$-test. Consider the Cobb-Douglas production function. Recall that the general Cobb-Douglas production function is $Q=AL^\\lambda K^\\mu$. Now, consider the production function:\n",
    "\n",
    "$$\n",
    "Q_t = \\beta_0 + \\beta_1L_t + \\beta_2K_t + \\epsilon_t\n",
    "$$\n",
    "where:\n",
    "- $Q_t$ is the natural log of total output in the USA in year $t$\n",
    "- $L_t$ is the natural log of labour input in the USA in year $t$\n",
    "- $K_t$ is the natural log of capital input in the USA in year $t$\n",
    "- $/epsilon_t$ is a well-behaved stochastic term\n",
    "\n",
    "Since that it can be shown that a Cobb-Douglas production function with constant returns to scale is one where $\\beta_1$ and $\\beta_2$ add up to exactly one, so the null hypothesis to be tested is\n",
    "$$\n",
    "\\begin{align*}\n",
    " \\text{H}_0 & \\text{: }\\beta_1+\\beta_2 = 1\\\\ \n",
    " \\text{H}_\\text{A} & \\text{: } \\text{otherwise}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "To test this null hypothesis with the ${F}$-test, we run regressions on the unconstrained () and and equation that is constrained to conform to the null hypothesis. To create such a constrained equation, we solve the null hypothesis for $\\beta_2$ and substitute into () to form:\n",
    "$$\n",
    "\\begin{align}\n",
    "Q_t &= \\beta_0 + \\beta_1L_t + (1- \\beta_1)K_t + \\epsilon_t\\\\\n",
    "Q_t &= \\beta_0 + \\beta_1(L_t - K_t) + K_t + \\epsilon_t\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and, rearranging $K_t$ to the left side of the equation yields the constrained equation\n",
    "$$\n",
    "\\begin{align}\n",
    "(Q_t-K_t) &= \\beta_0 + \\beta_1(L_t -K_t) + \\epsilon_t\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Equation () will be the equation that will hold if our null hypothesis were correct. To run an ${F}$-test on our null hypothesis of constant returns to scale, we need to run regressions on the constrained () and the unconstrained () and compare the fits of the two equations with the ${F}$-ratio from (). If we use annual US data, we obtain an unconstrained equation of\n",
    "$$\n",
    "\\begin{align}\n",
    "\\label{eg5_18}\n",
    "\\begin{split}\n",
    "\\hat{Q_t} &= -38.08 - {1.28L_t} + {0.72K_t}\\\\\n",
    "&\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\> (0.30) \n",
    "\\>\\>\\>\\>\\>\\>\\> (0.05)\\\\\n",
    "t&=\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\> 4.24 \n",
    "\\>\\>\\>\\>\\>\\>\\>\\>\\>\\> 13.29\\\\\n",
    "N&=24\\quad\\quad\\bar{R^2}=0.997 \\quad\\quad F=4118.9\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If we run the constrained equation and substitute the appropriate $\\text{RSS}$ into (), we obtain $F=16.26$. When this $F$ is compared to a $5\\%$ critical ${F}$-value of (with $N=21$ and $M=1$) only $F_C=$4.32. The degrees of freedom in the numerator is only $1$ because one coefficient has been eliminated from the equation by the constraint, the value is much higher so we reject the null hypothesis that constant returns to scale characterize the US economy. Interestingly, the sum of the estimated regression coefficients $\\beta_1+\\beta_2=2.00$ so there is a drastic increase returns to scale. However since $\\beta_1 > 1$ and the slope coefficient must be between 0 and 1, caution should be taken before we comfortably reach this conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different use of the ${F}$-test involves testing null hypotheses that apply to various subsets of the coefficients in the equation. Consider a problem of testing the significance of seasonal dummies. **Seasonal dummies** are dummy variables that are used to account for seasonal variation in the data in time-series models. In a quarterly model, if\n",
    "$$\n",
    "\\begin{align*}\n",
    "X_{1t} &= \\begin{cases}\n",
    "{1 \\text{ in quarter 1}}\\\\{0 \\text{ otherwise}}\n",
    "\\end{cases}\\\\\n",
    "X_{2t} &= \\begin{cases}\n",
    "{1 \\text{ in quarter 2}}\\\\{0 \\text{ otherwise}}\n",
    "\\end{cases}\\\\\n",
    "X_{3t} &= \\begin{cases}\n",
    "{1 \\text{ in quarter 3}}\\\\{0 \\text{ otherwise}}\n",
    "\\end{cases}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "then\n",
    "$$\n",
    "\\begin{equation}\n",
    "Y_t = \\beta_0 + \\beta_1X_{1t} + \\beta_2X_{2t} + \\beta_3X_{3t} + \\beta_4X_{4t} + \\epsilon_{t} \n",
    "\\end{equation}$$\n",
    "\n",
    "where $X_4$ is a non-dummy independent variable and $t$ is quarterly. 3 dummy variables are required to represent four seasons (simply because the last season is in play if $X_{1t}=X_{2t}=X_{3t}=0$. In this formulation $\\beta_1$ shows the extent to which the expected value of $Y$ in the first quarter differ from its expected value in the fourth quarter, the omitted condition. The other variables $\\beta_2$ and $\\beta_3$ can be interpreted similarly.\\\\ \n",
    "\n",
    "Inclusion of a set of seasonal dummies \"deseaonalizes\" Y and any independent variables that are not seasonally adjusted. This procedure may be used as $Y$ and $X_4$ are not \"seasonally adjusted\" prior to estimation. In this case, the null hypothesis is that there is *no seasonality*.\n",
    "$$\n",
    "\\begin{align*}\n",
    " \\text{H}_0 & \\text{: }\\beta_1 = \\beta_2 = \\beta_3 = 0\\\\ \\text{H}_\\text{A} & \\text{: } \\text{H}_1 \\text{ is not true}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The constrained equation would then be $Y=\\beta_0 + \\beta_4X_4 + \\epsilon$. To determine whether the whole set of seasonal dummies should be included, the fit of the estimated constrained equation would be compared to the fit of the estimated unconstrained equation by using the ${F}$-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
