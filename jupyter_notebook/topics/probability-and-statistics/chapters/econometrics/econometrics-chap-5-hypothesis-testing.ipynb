{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three topics that are central to hypothesis testing are\n",
    "- the specification of the hypothesis to be tested\n",
    "- the decision rule to use in deciding whether to rejected the hypothesis\n",
    "- the kinds of errors that might be encountered if the application of the decision rule to the appropriate statistics yields an incorrect reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null and Alternative Hypothesis\n",
    "\n",
    "The first step in hypothesis testing is to state the hypotheses to be tested. The **null hypothesis** typically is a statement of the values that the researcher does *not* expect. The notation used to specify the null hypothesis is $\\text{H}_0\\text{:}$ followed by a statement of the range of values you *do not expect*. For example if you expect a positive coefficient, then you do not expect a zero or negative coefficient and so the null hypothesis is $\\text{H}_0\\text{: } \\beta \\leq 0$\n",
    "\n",
    "The **alternative hypothesis** is a statement of the values that the researcher expects. The notation used to specify the alternative hypothesis is $\\text{H}_\\text{A}$: followed by a statement of the range of values you expect. Continuing from the previous example, if you expect a positive coefficient, then the alternative hypothesis is $\\text{H}_\\text{A}\\text{: } \\beta > 0$. As a whole, the expression is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{H}_0\\text{: }& \\beta \\leq 0 \\\\\n",
    "\\text{H}_\\text{A}\\text{: }& \\beta > 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Alternatively if you expect a negative coefficient then\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{H}_0\\text{: }& \\beta \\geq 0 \\\\\n",
    "\\text{H}_\\text{A}\\text{: }& \\beta < 0\n",
    "\\end{align*}\n",
    "$$\n",
    "This is for a **one-sided test** because the alternative hypotheses have values only on one side of the null hypothesis. Another approach is the **two-sided test** (or *two-tailed test*) where the alternative hypothesis has values on both sides of the null hypothesis. This is useful if the researcher does not expect $\\beta$ to be equal to zero but is unsure to expect a positive or negative value. For a two-sided test around zero, the null and alternative hypotheses are:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{H}_0\\text{: }& \\beta = 0 \\\\\n",
    "\\text{H}_\\text{A}\\text{: }& \\beta \\neq 0\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type I and Type II Errors\n",
    "\n",
    "The typical testing technique in econometrics is to hypothesize an expected sign / value for each regression coefficient and then to determine whether to reject the null hypothesis. Since the regression coefficients are only estimates of the true population parameters, it would be unrealistic to think that conclusions drawn from regression analysis will always be right.\n",
    "\n",
    "There are two kinds of errors that we make in such hypothesis testing, namely **Type I** errors where we reject a true null hypothesis and **Type II** errors where we do not reject a false null hypothesis.\n",
    "\n",
    "Suppose we have the null and alternative hypothesis as \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{H}_0\\text{: }& \\beta \\leq 0 \\\\\n",
    "\\text{H}_\\text{A}\\text{: }& \\beta > 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "There are two distinct possibilities. \n",
    "\n",
    "1. Even if the true parameter $\\beta$ is not positive, the estimate obtained by the researcher may be sufficiently positive to lead to the rejection of the null hypothesis that $\\text{H}_0\\text{: } \\beta \\leq 0$. This is a Type I error. We rejected the truth.\n",
    "\n",
    "2. Alternatively, we can obtain an estimate of $\\beta$ that is not close enough to zero to be considered \"not significantly positive\". Such a result may lead the researcher to not reject the null in favour of the alternative. This is a Type II Error. We have failed to reject a false null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Rules of Hypothesis Testing\n",
    "\n",
    "In testing a hypothesis, a **decision rule** is a method to determine when the null hypothesis can be rejected. Typically, it depends on the magnitude of the sample statistic compared with a preselected *critical value*.\n",
    "\n",
    "A decision rule is formulated *before* regression estimates are obtained. The range of possible values of $\\hat{\\beta}$ is divided into two regions, a *rejection* region and an \"*acceptance*\" region. The terms are expressed *relative to the null hypothesis*. The **critical value** is a value that divides the \"acceptance\" region from the \"rejection\" region when testing a null hypothesis.\n",
    "\n",
    "To use a decision rule, we need to select a critical value. Consider the one-sided test  $\\text{H}_0\\text{: }\\beta \\leq 0$ and $\\text{H}_\\text{A}\\text{: } \\beta > 0$ and let the critical value be $1.8$. If the observed $\\hat{\\beta}$ is greater than $1.8$, then we reject the null hypothesis because the value falls into the rejection region. Similarly, any observed value, let's say $\\hat{\\beta'}$ where $\\hat{\\beta'} < 1.8$ can be seen to fall in the \"acceptance\" region. We can also see that the rejection region is the probability that the null hypothesis is rejected if it is, in fact true. This also means that the Type I Error takes this definition. Formally, the Type I Error is the probability of rejecting the null hypothesis, when it is in fact true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $t$-Test\n",
    "\n",
    "The $t$-test is usually used to test hypotheses about individual regression slope coefficients. It is easy to use and it is appropriate when the stochastic error term is normally distributed and when the variance of that distribution must be estimated.\n",
    "\n",
    "### The $t$-Statistic\n",
    "\n",
    "Fore a typical multiple regression equation\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1X_{1i} + \\beta_2X_{2i} + \\epsilon_i \\label{eg5_1}\n",
    "$$\n",
    "\n",
    "we can calculate $t$-values for each of the estimated coefficients in the equation. $t$-tests are usually done only on slope coefficients and for these, the relevant form of the **$t$-statistic** for the $k$-th coefficient is\n",
    "$$\n",
    "\\begin{align}\n",
    "t_k = \\frac{\\hat{\\beta_k}-\\beta_{H_0}}{\\text{SE}(\\hat{\\beta_k})}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    ", $k=1, 2, \\cdots, K$\n",
    "\n",
    "where \n",
    "- $\\hat{\\beta_k}$ is the estimated value of the regression coefficient of the  $k$-th variable\n",
    "- $\\beta_{H_0}$ is the critical value implied by the null hypothesis of the $k$-th variable\n",
    "- SE($\\hat{\\beta_k}$) is the estimated standard error of $\\hat{\\beta_k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most regression hypotheses test whether a particular regression coefficient is significantly from $0$, $\\beta_{H_0}$ is typically $0$ and the most used form of the $t$-statistic becomes:\n",
    "$$\n",
    "t_k = \\frac{\\hat{\\beta_k}-0}{\\text{SE}(\\hat{\\beta_k})}\n",
    "$$\n",
    "$k=1, 2, \\cdots, K $, which simplifies to\n",
    "$$\n",
    "t_k = \\frac{\\hat{\\beta_k}}{\\text{SE}(\\hat{\\beta_k})}\n",
    "$$\n",
    "\n",
    "$k=1, 2, \\cdots, K $ or the estimated coefficient divided by the standard error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Critical $t$-value and the $t$-Test Decision Rule\n",
    "\n",
    "To decide whether to reject the null hypothesis based on a calculated $t$-value, we use a critical $t$-value. A **critical $t$-value** is the value that distinguishes the \"acceptance\" region from the \"rejection\" region. The critical $t$-value, $t_C$, is selected from a $t$-table depending on whether it is one-sided or two-sided, the level of Type I Error specified and the degrees of freedom $N-K-1$. The level of Type I Error is also known as the **level of significance** of that test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a $t$-value, $t_k$ and a critical $t$-value, $t_C$ has been calculated, we reject the null hypothesis if $|t_k| > t_C$ AND the $t_k$ has the sign implied by H$_\\text{A}$. In short,\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "- Reject H$_0$ if  $|t_k| > t_C$ **AND** if $t_k$ also has the sign implied by H$_\\text{A}$.<br/>\n",
    "- Do not reject H$_0$ otherwise.\n",
    "</div>\n",
    "\n",
    "The decision rule works for calculated $t$-values and critical $t$-values for one-sided hypotheses around zero:\n",
    "\n",
    "\\begin{align*}\n",
    " \\text{H}_0\\text{: }\\beta_k \\leq 0 \\text{ and } \\text{H}_\\text{A}\\text{: } \\beta_k > 0\\\\\n",
    " \\text{H}_0\\text{: }\\beta_k \\geq 0 \\text{ and } \\text{H}_\\text{A}\\text{: } \\beta_k < 0\n",
    "\\end{align*}\n",
    "\n",
    "or for two-sided hypotheses around zero:\n",
    "\n",
    "\\begin{align*}\n",
    " \\text{H}_0\\text{: }\\beta_k = 0 \\text{ and } \\text{H}_\\text{A}\\text{: } \\beta_k \\neq 0\n",
    "\\end{align*}\n",
    "\n",
    "around values other than zero. The one-sided test is\n",
    "\n",
    "\\begin{align*}\n",
    " \\text{H}_0\\text{: }\\beta_k \\leq S \\text{ and } \\text{H}_\\text{A}\\text{: } \\beta_k > S\\\\\n",
    " \\text{H}_0\\text{: }\\beta_k \\geq S \\text{ and } \\text{H}_\\text{A}\\text{: } \\beta_k < S\n",
    "\\end{align*}\n",
    "\n",
    "or for two-sided hypotheses around zero:\n",
    "\n",
    "\\begin{align*}\n",
    " \\text{H}_0\\text{: }\\beta_k = S \\text{ and } \\text{H}_\\text{A}\\text{: } \\beta_k \\neq S\n",
    "\\end{align*}\n",
    "\n",
    "The decision rule fo all the above is the same. Reject the null hypothesis if $|t_k|>t_C$ and has the same sign as the coefficient implied by H$_\\text{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Level of Significance\n",
    "\n",
    "It is necessary to pick a level of significance before a critical $t$-value could be looked up. The phrase \"significantly positive\" is interpreted as $\\text{H}_0\\text{: }\\beta_k \\leq 0$ being rejected in favour of $\\text{H}_\\text{A}\\text{: } \\beta_k > 0$ according to the pre-established decision rule which was set up with a given level of significance. The **level of significance** indicates the probability of observing an estimated $t$-value greater than the critical $t$-value if the null hypothesis were correct. It measures the amount of Type I Error implied by a particular critical $t$-value. If the level of significance is $10\\%$ and we reject the null hypothesis at that level, then this result would have occured only $10\\%$ of the time that the null hypothesis is indeed correct.\n",
    "\n",
    "Beginning econometricians assume that the lower the level of significance the better. A low level of signifance means a low probability of making a Type I Error. However an extremely low level of significance also dramatically increases the probability of making a Type II Error.\n",
    "\n",
    "Generally, we use a $5\\%$ level of significance except in circumstances where you know something unusual about the relative costs of making Type I or Type II errors. For example, if making a Type II Error is extremely costly then it would be reasonable to revise the level of significance up to $10\\%$.\n",
    "\n",
    "If we can reject a null hypothesis at the $5\\%$ level of significance we can say that the coefficient is \"statistically significant\" at the $5\\%$ level. Since the $5\\%$ level is arbitrary, we should not jump to conclusions about the value of a variable simply because its coefficients misses being significant by a small amount; if a different level of significance had been chosen the result might be different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals\n",
    "\n",
    "A **confidence interval** is a range which contains the true value of an item a specific percentage of the time. If we could take repeated samples, a $90\\%$ confidence interval would contain the true value in $90%$ of $100$ of these repeated samples. For an estimated regression coefficient, the confidence interval can be calculated using the two-sided critical $t$-value and the standard error of the estimated coefficent:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{Confidence Interval} = \\hat{\\beta} \\pm t_C \\cdot \\text{SE}(\\hat{\\beta})\n",
    "\\end{equation}\n",
    "$$\n",
    "If a $90\\%$ confidence interval for $\\hat{\\beta_P}$ would be $0.3547 \\pm 1.699\\times.0727$ or $0.3547 \\pm 0.1235$, we are confident $90\\%$ of the time that the true coefficient will fall between $0.2312$ and $0.4782$ or, Mathematically, $0.2312 \\leq \\hat{\\beta_P} \\leq 0.4782$.\n",
    "\n",
    "To understand the relationship between confidence intervals and hypothesis testing, if a hypothesized border value, $\\beta_{H_0}$, falls within the $90\\%$ confidence interval for an estimated coefficient then we are not able to reject the null hypothesis at the $10\\%$ level of significance in a two-sided test. On the other hand, if $\\beta_{H_0}$ falls outside the $90\\%$ confidence interval the we can reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $p$-Values\n",
    "\n",
    "An alternative approach to the $t$-test is the $p$-test based on a measure called the \t$p$-value, or *marginal significance level*. a $p$-value for a $t$-score is the probability of observing a $t$-score that size or bigger if the null hypothesis were true.\n",
    "\n",
    "A $p$-value is a probability, so $0 \\leq {p}\\text{-value} \\leq 1$. It tells us the lowest level of significance at which we could reject the null hypothesis. A small $p$-value casts doubt on the null hypothesis, so to reject the null hypothesis, we need a low $p$-value.\n",
    "\n",
    "To use a $p$-value to run a $t$-test, let your level of significance be $0.05$. Reject the null hypothesis as long as the $p$-value is lower than $0.05$ and the sign of $\\hat{\\beta_k}$ is in the direction as $\\text{H}_\\text{A}$. Thus, the $p$-value decision rule is\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Reject H$_0$ if  $p\\text{-value}_k < \\text{level of significance}$ **AND** if $\\hat{\\beta_k}$ also has the sign implied by $\\text{H}_\\text{A}$. Do not reject H$_0$ otherwise.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of $t$-Tests \n",
    "\n",
    "Consider a simple model of aggregate retail sales of new cars that hypothesizes the sales of new cars ($Y$) are a function of real disposable income ($X_1$) and the average retail price of a new car adjusted by the consumer price index ($X_2$). After reviewing literature you have decided to add a third independent variable, the number of sports utility vehicles sold ($X_3$). The following model is hypothesized:\n",
    "$$\n",
    "\\begin{equation}\n",
    "Y = f(\\overbrace{X_1}^+, \\overbrace{X_2}^-, \\overbrace{X_3}^-) + \\epsilon\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Using $(1)$, $\\beta_1$ is expected to be positive while $\\beta_2$ and $\\beta_3$ are expected to be negative. Based on these values, the respective null and alternative hypotheses are:\n",
    "\\begin{align*}\n",
    "\\text{H}_0 & \\text{: }\\beta_{X_1} \\leq 0 \\\\ \\text{H}_\\text{A} & \\text{: } \\beta_{X_1} > 0\\\\ \\\\\n",
    "\\text{H}_0 & \\text{: }\\beta_{X_2} \\geq 0 \\\\ \\text{H}_\\text{A} & \\text{: } \\beta_{X_2} < 0\\\\ \\\\\n",
    "\\text{H}_0 & \\text{: }\\beta_{X_3} \\geq 0 \\\\ \\text{H}_\\text{A}\\ & \\text{: } \\beta_{X_3} < 0\n",
    "\\end{align*}\n",
    "\n",
    "Consider that there are 10 observations and you are picking the $5\\%$ as the level of significance. The number of degrees of freedom is $10-3-1=6$. For all 3 variables, $t_C = 1.943$\n",
    "\n",
    "After running the regression, the OLS computer package produces:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{Y_t} &= 1.30+4.91X_{1t}+0.00123X_{2t}-7.14X_{3t}\\\\\n",
    "&\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\> (2.38) \\>\\>\\>\\>\\>\\>\\>\\>\\> (0.00022)\n",
    "\\>\\>\\>\\>\\>\\>\\>\\>\\>(71.38)\\\\\n",
    "t&=\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\> -2.1 \n",
    "\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\> 5.6\n",
    "\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>\\>-0.1\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where\n",
    "- $Y$ is new car sales in ('00,000) units in year $t$\n",
    "- $X_1$ is real U.S. disposable income in \\$('000,000,000) in year $t$\n",
    "- $X_2$ is average retail price of a new car in in year $t$\n",
    "- $X_3$ is the number of sports utility vehicles sold in year $t$ in ('000,000)\n",
    "\n",
    "By applying the decision rule based on the hypotheses that was set up,\n",
    "\n",
    "- reject H$_0$ for $\\beta_1$ if the $t$-value is greater than 1.943. Hence, reject $\\text{H}_0$ in favour of $\\text{H}_\\text{A}$ for $X_1$.\n",
    "- reject H$_0$ for $\\beta_2$ if the $t$-value is smaller than -1.943. Hence, do not reject $\\text{H}_0$ in favour of $\\text{H}_\\text{A}$ for $X_2$. In this case, the absolute value exceeds the critical value but the sign does not agree.\n",
    "- reject H$_0$ for $\\beta_3$ if the $t$-value is smaller than -1.943. Hence, do not reject $\\text{H}_0$ in favour of $\\text{H}_\\text{A}$ for $X_3$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Two-Sided $t$-Tests\n",
    "\n",
    "The two-sided tests are used to test if\n",
    "\n",
    "- if an estimated coefficient is significantly different from zero or\n",
    "- if an estimated coefficient is significantly different from a specific nonzero value\n",
    "\n",
    "Consider back the Woody's Restaurant example. We suspect that the impact of the average income on an area on the total customers going out to dinner is ambiguous. High incomes might mean Woody's is an inferior good and they dine at another restaurant. To do so, run a two-sided test around zero to determine whether or not the estimated coefficient of income is significantly different from zero *in either direction*. The hypothesis set up is $\\text{H}_0\\text{: }\\beta_I = 0$ and $\\text{H}_\\text{A}\\text{: } \\beta_I \\neq 0$\n",
    "\n",
    "Keeping the level of significance to be at $5\\%$, the critical values are now $2.045$ and $-2.045$. That means, reject the null hypothesis if the $t$-value is outside this range. The calculated $t$-value is $2.37$. Since it is outside the \"acceptance\" region, we reject the null hypothesis in favour of the alternative hypothesis. \n",
    "Because of the $+$ sign, we say that the higher the income of the population, the more check volume Woody's will get. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
